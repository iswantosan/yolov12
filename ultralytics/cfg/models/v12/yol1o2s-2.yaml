# YOLOv12 ðŸš€, AGPL-3.0 license ?? 87.6
# YOLOv12 object detection model with P2-P5 outputs - MEMORY EFFICIENT
# Optimizations:
# - Minimal A2C2f usage (only in P4 backbone) to save memory
# - C3k2 in head for lightweight feature fusion
# - P2-P5 detection untuk multi-scale objects

# Parameters
nc: 1 # number of classes
scales: # model compound scaling constants
  # [depth, width, max_channels]
  s: [0.50, 0.50, 1024]

# YOLO12s backbone - Memory efficient for small object detection
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 2, C3k2, [256, False, 0.25]] # 2-P2/4 (original depth) + ECA
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 2, C3k2, [512, False, 0.25]] # 4-P3/8 (C3k2ECA instead of A2C2f to save memory)
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 2, A2C2f, [512, True, 1]] # 6-P4/16 (reduced from 4 to 2)
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 4, A2C2f, [1024, True, 1]] # 8-P5/32

head:
  # ---------- P5 HEAD (dari backbone P5 = 8) ----------
  - [8, 1, C3k2ECA, [512, False, 0.25]] # 9: P5 head (C3k2ECA instead of A2C2f to save memory)

  # ---------- P4 HEAD (dari backbone P4 = 6) ----------
  - [6, 1, C3k2ECA, [256, False, 0.25]] # 10: P4 head (C3k2ECA instead of A2C2f to save memory)

  # ---------- P4 -> P3 ----------
  - [10, 1, nn.Upsample, [None, 2, "nearest"]] # 11: upsample P4 -> P3 (16 -> 8)
  - [[-1, 4], 1, Concat, [1]] # 12: concat dengan backbone P3 (4)
  - [-1, 1, C3k2ECA, [256, False, 0.25]] # 13: P3 head (reduced, no channel reduction) + ECA

  # ---------- P3 -> P2 ----------
  - [13, 1, nn.Upsample, [None, 2, "nearest"]] # 14: upsample P3 -> P2 (8 -> 4)
  - [[-1, 2], 1, Concat, [1]] # 15: concat dengan backbone P2 (2)
  - [-1, 1, C3k2ECA, [256, False, 0.25]] # 16: P2 head (C3k2ECA instead of A2C2f to save memory)

  # ---------- Detect dengan P2â€“P5 ----------
  - [[16, 13, 10, 9], 1, Detect, [nc]] # 17: Detect(P2, P3, P4, P5)
